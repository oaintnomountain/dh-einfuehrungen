{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Beispiel Webscraping mit Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76365c11273e69cb",
   "metadata": {},
   "source": [
    "## Aufgabe: \n",
    "Sammle die Abstracts aller Artikel der aktuellen Ausgabe von DH Quarterly (https://www.digitalhumanities.org/dhq) und Liste sie zusammen mit dem Titel des Artikels und den Infos zur Autor*innenschaft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f248da78f964312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-30T12:08:53.632645Z",
     "start_time": "2024-10-30T12:08:53.533215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Titel': 'Introduction to the Special Issue: Using Visual AI Applied to Digital Archives', 'Autor_in': 'Lise Jaillant, Loughborough University, UK', 'Abstract': 'This Special Issue focuses on the theme ofâ\\x80¯ Using Visual AI Applied to Digital Archives. It seeks to improve the discoverability, accessibility, and use of digitised cultural archives by working at the crossroads between the humanities (including visual studies, history, and ethics), computer science, and other fields (including information and archival studies). This special issue is an invitation to work collaboratively, across disciplines and sectors, to address challenges associated with AI and fully embrace the potentialities of technology to make visual archives more accessible in an ethical way.'}, {'Titel': 'Augmenting Access to Embodied Knowledge Archives: A Computational Framework', 'Autor_in': 'Giacomo Alliata, Laboratory for Experimental Museology, EPFL, Switzerland; Yumeng Hou, Laboratory for Experimental Museology, EPFL, Switzerland; Sarah Kenderdine, Laboratory for Experimental Museology, EPFL, Switzerland', 'Abstract': \"With the burgeoning use of digital technologies in safeguarding intangible and living heritage, memory institutions have produced a significant body of material yet to be made accessible for public transmission. The quest for new ways to unlock these massive collections has intensified, especially in the case of embodied knowledge embedded in complex formats, such as audiovisual and motion capture data. This study examines a computational workflow that combines posture recognition and movement computing to bridge the gap in accessing digital archives that capture living knowledge and embodied experiences. By reflecting on how embodied knowledge is sustained and potentially valorised through human interaction, we devise a series of methods utilising vision-based feature extraction, pose estimation, movement analysis, and machine learning. The goal is to augment the archival experience with new modes of exploration, representation, and embodiment. This article reports the computational procedures and algorithmic tools inspected through two use cases. In the first example, we visualise the archives of the Prix de Lausanne, a collection of 50 years of video recordings of dance performances, for archival exploration through the dancers' poses. In another experiment, movement encoding is employed to allow multimodal data search via embodied cues in the Hong Kong Martial Arts Living Archive, a comprehensive documentation of the living heritage of martial arts that is chiefly comprised of motion-captured performances by masters. Though holding different application purposes, both projects operate on the proposed framework and extract archive-specific features to create a meaningful representation of human bodies, which reveals the versatile applications that computational capacities can achieve for embodied knowledge archives. The practices also represent a model of interdisciplinary involvement where the archivists, computists, artists, and knowledge holders join hands to renew strategies for archival exploration and heritage interpretation in a new light.\"}, {'Titel': 'Sensitivity and Access: Unlocking the Colonial Visual Archive with Machine Learning', 'Autor_in': \"Jonathan Dentler, Catholic University of Paris; German Historical Institute, Washington D.C.; Lise Jaillant, Loughborough University, UK; Daniel Foliard, UniversitÃ© Paris CitÃ©, LARCA (UMR 8225); Julien Schuh, UniversitÃ© Paris Nanterre; Maison des Sciences de l'Homme Mondes\", 'Abstract': 'In recent decades, archival institutions have digitized an enormous quantity of material under the rubric of open access, including from colonial archives. However, much of the most sensitive material from these collections remains undigitized or difficult to discover and use. More recently, a critical reconsideration of open digital access has also taken place, particularly when it comes to sensitive material from the colonial archive. Collectively, this has created a situation in which the colonial photography archive risks becoming overly sanitized as well as difficult to navigate and analyze. In this article, we propose that critical and transparent multimodal artificial intelligence (AI) offers a way to improve access to colonial archives for researchers and the public, without losing sight of the need for ethical approaches to sensitive visual materials. The EyCon (Early Conflict Photography and Visual AI) project assembled a large database of sensitive visual materials from colonial conflicts and developed experimental multi-modal computer vision tools with which to analyze it. Though this tool has not yet been applied at scale or quantitatively compared with other approaches, we are able to propose modes of inquiry for other researchers to explore as they create new research tools. On a more hypothetical or theoretical level, we consider how the use of computational tools to facilitate access to and analysis of sensitive historical materials is compatible with or even beneficial for more ethical approaches to such materials. We conclude with several promising areas for critically integrating AI into the digital colonial archive, while also expanding on some limitations of such techniques.'}, {'Titel': 'AI and Medical Images: Addressing Ethical Challenges to Provide Responsible Access to Historical Medical Illustrations', 'Autor_in': 'Lise Jaillant, Loughborough University, UK; Katherine Aske, Edinburgh Napier University, UK', 'Abstract': 'This article examines the ethical considerations and broader issues around access to digitised historical medical images. These illustrations and, later, photographs are often extremely sensitive, representing disability, disease, gender, and race in potentially harmful and problematic ways. In particular, the original metadata for such images can include demeaning and sometimes racist terms. Some of these images show sexually explicit and violent content, as well as content that was obtained without informed consent. Hiding these sensitive images can be tempting, and yet, archives are meant to be used, not locked away. Through a series of interviews with 10 archivists, librarians, and researchers based in the UK and US, the authors show that improved access to medical illustrations is essential to produce new knowledge in the humanities and medical research, as well as to bridge the gap between historical and modern understandings of the human body. Improving access to medical illustration can also help to address the â\\x80\\x9cgender data gapâ\\x80\\x9d, which has acquired mainstream visibility thanks to the work of activists such as Caroline Criado-Perez, the author of Invisible Women: Data Bias in a World Designed for Men. Users of historical medical archives are therefore a diverse group, which includes researchers in medicine, history, and medical and digital humanities, as well as artists, journalists, and activists. In order to improve discoverability and facilitate access to these archives in an ethical way, this article highlights the importance of appropriate metadata, which can be enhanced through the use of artificial intelligence (AI) tools. Indeed, AI can be used to create new metadata when original information is incomplete or is missing altogether, or when it includes problematic language. AI can also help with the disaggregation of data by gender and/or racial ethnicity. Moreover, it can recommend similar images to allow users to explore other parts of the collections. However, AI can also pose issues, for example when it suggests inappropriate metadata or similarity search results. Keeping humans in the loop is therefore essential when applying AI to sensitive medical images. Ultimately, this article argues that access to sensitive images cannot be separated from responsibility. Recommendations are made to help cultural heritage institutions find the right balance, to provide access for research and education, and to also protect children and other vulnerable audiences from encountering images that can be described as shocking and even traumatising.'}, {'Titel': 'Capturing Captions: Using AI to Identify and Analyse Image Captions in a Large Dataset of Historical Book Illustrations', 'Autor_in': 'Julia Thomas, School of English Communication and Philosophy, Cardiff University; Irene Testini, Special Collections and Archives, Cardiff University', 'Abstract': 'This article outlines how AI methods can be used to identify image captions in a large dataset of digitised historical book illustrations. This dataset includes over a million images from 68,000 books published between the eighteenth and early twentieth centuries, covering works of literature, history, geography, and philosophy. The article has two primary objectives. First, it suggests the added value of captions in making digitized illustrations more searchable by picture content in online archives. To further this objective, we describe the methods we have used to identify captions, which can effectively be re-purposed and applied in different contexts. Second, we suggest how this research leads to new understandings of the semantics and significance of the captions of historical book illustrations. The findings discussed here mark a critical intervention in the fields of digital humanities, book history, and illustration studies.'}, {'Titel': \"Deep Learning for Historical Cadastral Maps and Satellite Imagery Analysis: Insights from Styria's Franciscean Cadastre\", 'Autor_in': 'Wolfgang Thomas GÃ¶derle, University of Innsbruck; Max Planck Institute of Geoanthropology; Fabian Rampetsreiter, University of Graz; Christian Macher, Know Center; Katrin Mauthner, Know Center; Oliver Pimas, Know Center', 'Abstract': 'Cadastres from the 19th century are a complex as well as rich source for historians and archaeologists, the study of which presents great challenges. For archaeological and historical remote sensing, we have trained several Deep Learning models, CNNs, and Vision Transformers to extract large-scale data from this knowledge representation. We present the principle results of our work here and demonstrate our browser-based tool that allows researchers and public stakeholders to quickly identify spots that featured buildings in the 19th century Franciscean cadastre. The tool not only supports scholars and fellow researchers in building a better understanding of the settlement history of the region of Styria; it also helps public administration and fellow citizens to swiftly identify areas of heightened sensibility with regard to the cultural heritage of the region.'}, {'Titel': 'â\\x80\\x9cOpenâ\\x80\\x9d or â\\x80\\x9cCloseâ\\x80\\x9d Research Instruments? Conflicting Rationales in the Organization of Early Digital Medieval History in Europe (1960â\\x80\\x931990).', 'Autor_in': 'Edgar Lejeune, Vossius Center for the History of Humanities and Sciences (University of Amsterdam)', 'Abstract': 'From the late 1940s onwards, humanities scholars used computers in order to create new types of research instruments, e.g., databases, digital scholarly editions of texts and/or archives, computer programs, etc. Their ambitions in doing so consisted in saving time in tedious, repetitive and error-prone scholarly tasks, enhancing the circulation of data and/or scholarly information, or even contributing to the â\\x80\\x9cprogressâ\\x80\\x9d of an entire discipline. Sharing these research instruments with interested colleagues was then crucial for these scholars. However, each of these humanities computing collectives developed at the time its own idiosyncratic procedures for editing, analyzing, and publishing computer-recorded material. This profoundly affected the possibility for these research instruments to circulate among scholars. In this article, I present how medievalists debated about a possible circulation of these digital research instruments in that context, and how it contributes to the development of an early â\\x80\\x9chumanities computingâ\\x80\\x9d organization in Europe. I show how medievalistsâ\\x80\\x99 ambitions raised a whole series of material and intellectual difficulties which are still essential in our current DH practices and organizations. What data should we edit (and thus, what data are worth sharing)? In what form should we publish these datasets? And do we need common rules for this purpose? I argue that a precise history of early DH communities highlights a strong continuity with contemporary DH issues as well as the importance of historical studies of our field.'}, {'Titel': 'Lilypond Music-Notation Software in the Digital-Humanities Toolbox', 'Autor_in': 'Andrew A. Cashner, University of Rochester', 'Abstract': 'The music-notation software Lilypond generates high-quality music typography from a plain-text input format; almost every aspect of the program can be customized and programmed, and the system lends itself well to automation and batch processing. Lilypond offers a â\\x80\\x9cminimal computingâ\\x80\\x9d alternative to bloated, costly, and hegemonic graphical programs. Like many free software tools, however, Lilypond still exacts a cost in time and training needed to overcome an unwieldly interface and adapt the tool for scholarly purposes. The author developed a system called lirio that enabled the production of two critical editions and a monograph in Lilypond (integrated with LaTeX). The system provides a new semantic-markup interface to Lilypond that enables scholars to think about typography separately from musical content; a range of expanded Lilypond functionality including incipit staves, mensural coloration brackets, and editorial annotations; and a stricter input format that makes Lilypond files easier to maintain. The author also developed the prototype ly2mei compiler to demonstrate how Lilypond files can be converted to MEI-XML, overcoming a major limitation in Lilypondâ\\x80\\x99s export abilities. The article argues that scholars will be best served by a simple, consistent, meaningful interface in a format that can be shared and converted. An extension of Lilypond like lirio demonstrates the considerable potential of this tool for enterprising and patient scholars whose needs are not met by other tools. Lilypond provides a case study for how to make open-source, free-license tools work for our own needs as digital humanists.'}, {'Titel': 'LemonizeTBX: Design and Implementation of a New Converter from TBX to OntoLex-Lemon', 'Autor_in': 'Andrea Bellandi, Institute for Computational Linguistics \"A. Zampolli\" CNR, Via Moruzzi 1, 56124, Pisa - Italy; Giorgio Maria Di Nunzio, Department of Information Engineering, University of Padova, Via Gradenigo 6/b, 35131 Padova, Italy; Silvia Piccini, Institute for Computational Linguistics \"A. Zampolli\" CNR, Via Moruzzi 1, 56124, Pisa - Italy; Federica Vezzani, Department of Linguistic and Literary Studies, University of Padova, Via Elisabetta Vendramini, 13 35137 Padova, Italy', 'Abstract': 'In this paper, we introduce LemonizeTBX, a converter that enhances interoperability between terminological and lexicographical frameworks, acknowledging their divergent data modelling approaches. First, we present the theoretical implications of a conversion from the TermBase eXchange (TBX) concept-oriented framework to the OntoLex-Lemon sense-centred standpoint within Semantic Web technologies. Then, we illustrate the prototype version of the converter, designed as an interactive tool engaging terminologists in the conversion process.'}, {'Titel': 'Towards a National Data Architecture for Cultural Collections: Designing the Australian Cultural Data Engine', 'Autor_in': 'Rachel Fensham, University of Melbourne; Australian Cultural Data Engine; Tyne Daile Sumner, Australian National University; Australian Cultural Data Engine; Nat Cutter, University of Melbourne; Australian Cultural Data Engine; George Buchanan, RMIT University; Rui Liu, University of Melbourne; Justin Munoz, Independent Scholar; James Smithies, Australian National University; Ivy Zheng, University of Newcastle; David Carlin, RMIT University; Erik Champion, University of South Australia; Hugh Craig, University of Newcastle; Scott East, University of New South Wales; Chris Hay, Flinders University; Lisa M. Given, RMIT University; John Macarthur, University of Queensland; David McMeekin, Curtin University; Joanna Mendelssohn, University of Melbourne; Deborah van der Plaat, University of Queensland', 'Abstract': 'This article summarises the aims, methods, information architecture, outputs, and innovations of the Australian Cultural Data Engine (ACD-Engine), a project that harnesses leading cultural databases to build bridges to research, industry, and government. The project investigates digital heritage collections, data ontologies, and interoperability, building an information architecture to enhance the open sharing of Australian cultural data. Working with a cross-disciplinary team, the ACD-Engine establishes conceptual and technical frameworks for better understanding the platforms and uses of cultural data across a range of national and international contexts. This new cyber-infrastructure advances cultural data aggregation and interoperability whilst prioritising data quality and domain distinctiveness to answer new research questions across disciplines. As such, the ACD-Engine provides a novel approach to data management and data modelling in the arts and humanities that has significant implications for digital collections, digital humanities, and data analytics.'}, {'Titel': 'Graph based modelling of prosopographical datasets. Case study: Romans 1by1', 'Autor_in': 'Rada Varga, BabeÈ\\x99-Bolyai University; Stefan Bornhofen, CY Cergy Paris University', 'Abstract': 'In this paper, we present and discuss a promising research avenue, that is the use of graph-based models and software for prosopographical data sets. Our case study will be constituted by Romans 1by1 (http://romans1by1.com/), a digital-born prosopography focusing on people attested in classical era inscriptions; it presently hosts approximately 18,000 open access persons files. The project aimed at employing new techniques and methodologies that come from other fields (i.e. computer science), in order to approach the study of ancient population in an innovative way, to ease the research, and to create an open-access tool, available for the academic community. In the scope of this paper, we use Romans1by1 as an example to explore the perspectives of ingesting the information from a prosopographical relational database into a graph database.'}, {'Titel': 'From Archive to Database: Using Crowdsourcing, TEI, and Collaborative Labor to Construct the Maria Edgeworth Letters Project', 'Autor_in': 'Hilary Havens, University of Tennessee, Knoxville; Eliza Alexander Wilcox, University of Tennessee, Knoxville; Meredith L. Hale, University of Tennessee, Knoxville; Jamie Kramer, University of Tennessee, Knoxville', 'Abstract': \"This article unpacks the archival, textual, and encoded layers that comprise the Maria Edgeworth Letters Project (MELP), an open-access digital archive containing the correspondence of the Anglo-Irish Regency author Maria Edgeworth and her circle. These layers reveal the impossibility of flattening or standardizing our work and instead advocate for a more inclusive and collaborative digital humanities model that accommodates both institutional and volunteer labor. Just as different methods were used to approach each archive and manage our project across multiple institutions, each transcription requires a different level of care, especially as various notes and collaborators are cited in the final project. Through the use of TEI, we can flexibly represent diverse aspects of each letter while still maintaining a database-readable structure. We endeavor to connect each person, place, or work identified in Edgeworth's letters and our database to a larger network of linked data in order to place our project in conversation with other archival resources. For entities that are unidentified or unknown, we create new name authority files or produce internal data files that can be viewed by our collaborators and users. MELP's flexible structure thus allows it to strive for interoperability while refusing to efface the individual traces of its collaborators, entities, and material artifacts.\"}, {'Titel': 'A Review of James Littleâ\\x80\\x99s The Making of Samuel Beckettâ\\x80\\x99s Not I / Pas moi, That Time / Cette fois and Footfalls / Pas (2021)', 'Autor_in': 'CÃ©line Thobois-Gupta, Trinity College Dublin', 'Abstract': 'This review highlights the main achievements of James Littleâ\\x80\\x99s The Making of Samuel Beckettâ\\x80\\x99s Not I / Pas moi, That Time / Cette fois and Footfalls / Pas (2021).'}, {'Titel': 'A Review of Feminist in a Software Lab: Difference + Design (2018)', 'Autor_in': 'Diane K. Jakacki, Bucknell University', 'Abstract': \"This review ofÂ Feminist in a Software Lab: Difference + Design (2018)Â considers Tara McPherson's ambitious and compelling reflections on the Vectors Lab and attendant journal housed at the University of Southern California, as well as the development of the Scalar web publication environment.\"}, {'Titel': 'The Humans and Algorithms of Music Recommendation: A Review of Computing Taste (2022)', 'Autor_in': 'Jacob Pleasants, University of Oklahoma', 'Abstract': 'In Computing Taste, Nick Seaver conducts an anthropological study of the technologists who design algorithmic music recommendation systems. He explores their ways of thinking and talking about music, taste, and computation to better understand their technological design approaches. By highlighting the humans behind the machines, Computing Taste shows how to think about computer algorithms as sociotechnical systems.'}, {'Titel': 'Digital Methods in Literary Criticism: A Review of Digital Humanities and Literary Studies (2022)', 'Autor_in': 'Lili Wang, Harbin Engineering University; Tianxiang Chen, Harbin Engineering University', 'Abstract': 'In Digital Humanities and Literary Studies, Martin Paul Eve discusses various cases of digital technology in the analysis of literary studies and examines how digital tools influence literary interpretation. Martin skillfully navigates the complex landscape of digital methodologies, offering readers a holistic view of the transformative influence of literary analysis.'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Die URL von der wir Inhalte auslesen wollen\n",
    "url = \"https://www.digitalhumanities.org/dhq/vol/18/2/index.html\"\n",
    "\n",
    "# Rufe die Webseite ab\n",
    "response = requests.get(url)\n",
    "\n",
    "# lese den Website Code in Beautiful Soup ein\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# finde alle Artikel\n",
    "artikelliste = soup.find_all(\"div\", class_=\"articleInfo\")\n",
    "\n",
    "# extrahiere die relevanten Informationen aus der Artikelliste und lösche Zeilenumbrüche, Tabs und doppelte Leerzeichen\n",
    "artikelinfo = []\n",
    "\n",
    "for artikel in artikelliste:\n",
    "    info = {\n",
    "        'Titel':\" \".join(artikel.find_all('a')[0].text.replace(\"\\n\", \"\").replace('\\t',' ').split()),\n",
    "        'Autor_in':\" \".join(artikel.find_all('div')[0].text.replace(\"\\n\", \"\").replace('\\t',' ').split()),\n",
    "        'Abstract':\" \".join(artikel.find_all('span', class_='abstract')[0].text.replace('\\n','').replace('\\t',' ').split())\n",
    "    }\n",
    "    artikelinfo.append(info)\n",
    "\n",
    "# Ausgabe der Artikelinfos auf Konsole    \n",
    "print(artikelinfo)\n",
    "\n",
    "# Speichern der Liste mit Titeln, Autor*innen und Abstracts\n",
    "spaltennamen = ['Titel', 'Autor_in', 'Abstract']\n",
    "with open('DHQ_Artikelliste.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=spaltennamen)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(artikelinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0334b99f8a40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
